# Interpretability Experiment


<!-- ABOUT THE PROJECT -->
## About The Project

This project explores different interpretability strategies to interpret tabular data at scale. In particular, it explores applications of ShAP to gradient boosting and NN models. 

Project aim:
* Compare feature extraction from black-box models to classical linear approaches
* Compare black-box model interpretations, seeing where these converge or diverge in meaningful ways
* Apply out-of-memory strategies that will enable both batched training of models, followed by model interpretation to unpack predictive components of the inputs


<!-- ROADMAP -->
## Roadmap

See the [open issues](https://github.com/justinwhatley/interpretability_experiment/issues) for a list of ideas and known issues.


<!-- CONTACT -->
## Contact
Project Link: [https://github.com/justinwhatley/interpretability_experiment]
